{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "!pip install torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LzbXENVacZ3",
        "outputId": "e342afd3-e012-4c88-eef6-9b7a6d46c028"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt20cpu)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt20cpu)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.10/dist-packages (1.6.3+pt20cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GATConv, MessagePassing\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.utils import from_networkx\n",
        "from nltk.corpus import wordnet as wn\n",
        "import requests\n",
        "import random\n",
        "# Define MPNN Class\n",
        "class MPNNLayer(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(MPNNLayer, self).__init__(aggr='mean')  # Mean aggregation\n",
        "        self.lin = nn.Linear(in_channels, out_channels)\n",
        "        self.edge_update = nn.Linear(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr=None):\n",
        "        # Start message passing\n",
        "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
        "\n",
        "    def message(self, x_j, edge_attr):\n",
        "        # Combine node features with edge features\n",
        "        return self.lin(x_j) + (self.edge_update(edge_attr) if edge_attr is not None else 0)\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        return F.relu(aggr_out)\n",
        "\n",
        "class MPNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MPNN, self).__init__()\n",
        "        self.mpnn1 = MPNNLayer(input_dim, hidden_dim)\n",
        "        self.mpnn2 = MPNNLayer(hidden_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr=None):\n",
        "        x = self.mpnn1(x, edge_index, edge_attr)\n",
        "        x = self.mpnn2(x, edge_index, edge_attr)\n",
        "        return self.fc(x)\n",
        "\n",
        "# Define GCN Class\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        return self.fc(x)\n",
        "\n",
        "# Define GAT Class\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim, heads=1)\n",
        "        self.conv2 = GATConv(hidden_dim, hidden_dim, heads=1)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        return self.fc(x)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkX0Obz9NbBl",
        "outputId": "57fcefc6-bc52-4b60-eea3-85d86e9d244a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pp4HTrlWEUm",
        "outputId": "6c197ed0-3feb-4b7e-8b83-085fcd00c1dd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- WordNet API Integration ----------------\n",
        "def build_wordnet_graph_api(root_synset, depth=2):\n",
        "    \"\"\"\n",
        "    Build a graph using WordNet API starting from a root synset.\n",
        "    Args:\n",
        "        root_synset (str): Starting synset (e.g., 'dog.n.01').\n",
        "        depth (int): Depth of traversal in WordNet hierarchy.\n",
        "    Returns:\n",
        "        G (nx.DiGraph): NetworkX directed graph.\n",
        "    \"\"\"\n",
        "    G = nx.DiGraph()\n",
        "    visited = set()\n",
        "\n",
        "    def add_edges(synset, current_depth):\n",
        "        if current_depth > depth or synset in visited:\n",
        "            return\n",
        "        visited.add(synset)\n",
        "\n",
        "        # Add hypernyms and hyponyms as edges\n",
        "        for hypernym in synset.hypernyms():\n",
        "            G.add_edge(synset.name(), hypernym.name(), relation='hypernym')\n",
        "            add_edges(hypernym, current_depth + 1)\n",
        "\n",
        "        for hyponym in synset.hyponyms():\n",
        "            G.add_edge(synset.name(), hyponym.name(), relation='hyponym')\n",
        "            add_edges(hyponym, current_depth + 1)\n",
        "\n",
        "    root = wn.synset(root_synset)\n",
        "    add_edges(root, 0)\n",
        "    return G\n",
        "\n",
        "def wordnet_to_torch_geometric(G):\n",
        "    \"\"\"\n",
        "    Convert WordNet NetworkX graph to PyTorch Geometric Data format.\n",
        "    \"\"\"\n",
        "    mapping = {node: idx for idx, node in enumerate(G.nodes)}\n",
        "    G = nx.relabel_nodes(G, mapping)\n",
        "\n",
        "    edge_index = torch.tensor(list(G.edges), dtype=torch.long).t().contiguous()\n",
        "    num_nodes = G.number_of_nodes()\n",
        "    x = torch.rand(num_nodes, 16)  # Random node features\n",
        "    y = torch.randint(0, 2, (num_nodes,))  # Random node labels for classification\n",
        "    return Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "# ---------------- ConceptNet API Integration ----------------\n",
        "def build_conceptnet_graph_api(concept, max_edges=1000):\n",
        "    \"\"\"\n",
        "    Build a graph using ConceptNet API.\n",
        "    Args:\n",
        "        concept (str): Concept to query from ConceptNet API (e.g., 'dog').\n",
        "        max_edges (int): Maximum number of edges to fetch.\n",
        "    Returns:\n",
        "        G (nx.DiGraph): NetworkX directed graph.\n",
        "    \"\"\"\n",
        "    url = f\"http://api.conceptnet.io/c/en/{concept}\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Failed to fetch data from ConceptNet API: {response.status_code}\")\n",
        "\n",
        "    data = response.json()\n",
        "    G = nx.DiGraph()\n",
        "    for edge in data['edges'][:max_edges]:\n",
        "        source = edge['start']['label']\n",
        "        target = edge['end']['label']\n",
        "        relation = edge['rel']['label']\n",
        "        G.add_edge(source, target, relation=relation)\n",
        "    return G\n",
        "\n",
        "def conceptnet_to_torch_geometric(G):\n",
        "    \"\"\"\n",
        "    Convert ConceptNet NetworkX graph to PyTorch Geometric Data format.\n",
        "    \"\"\"\n",
        "    mapping = {node: idx for idx, node in enumerate(G.nodes)}\n",
        "    G = nx.relabel_nodes(G, mapping)\n",
        "\n",
        "    edge_index = torch.tensor(list(G.edges), dtype=torch.long).t().contiguous()\n",
        "    num_nodes = G.number_of_nodes()\n",
        "    x = torch.rand(num_nodes, 16)  # Random node features\n",
        "    y = torch.randint(0, 2, (num_nodes,))  # Random node labels for classification\n",
        "    return Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "# ---------------- Metrics Calculation ----------------\n",
        "def calculate_mrr(predictions, labels):\n",
        "    \"\"\"\n",
        "    Calculate Mean Reciprocal Rank (MRR).\n",
        "    Args:\n",
        "        predictions (torch.Tensor): Model predictions (logits or probabilities).\n",
        "        labels (torch.Tensor): Ground truth labels.\n",
        "    \"\"\"\n",
        "    ranks = []\n",
        "    for i in range(len(labels)):\n",
        "        sorted_indices = predictions[i].argsort(descending=True)\n",
        "        rank = (sorted_indices == labels[i]).nonzero(as_tuple=True)[0].item() + 1\n",
        "        ranks.append(1.0 / rank)\n",
        "    return sum(ranks) / len(ranks)\n",
        "\n",
        "def calculate_hits_k(predictions, labels, k=10):\n",
        "    \"\"\"\n",
        "    Calculate Hits@K.\n",
        "    Args:\n",
        "        predictions (torch.Tensor): Model predictions (logits or probabilities).\n",
        "        labels (torch.Tensor): Ground truth labels.\n",
        "        k (int): Number of top predictions to consider.\n",
        "    \"\"\"\n",
        "    hits = 0\n",
        "    for i in range(len(labels)):\n",
        "        top_k_indices = predictions[i].argsort(descending=True)[:k]\n",
        "        if labels[i] in top_k_indices:\n",
        "            hits += 1\n",
        "    return hits / len(labels)\n",
        "\n",
        "# ---------------- Training and Evaluation ----------------\n",
        "def train(model, data, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    mrr, hits_10, loss = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            out = model(data.x, data.edge_index)\n",
        "            mrr += calculate_mrr(out, data.y)\n",
        "            hits_10 += calculate_hits_k(out, data.y, k=10)\n",
        "            loss += criterion(out, data.y).item()\n",
        "    size = len(loader.dataset)\n",
        "    return mrr / size, hits_10 / size, loss / size\n",
        "\n",
        "# ---------------- Main Experiment ----------------\n",
        "if __name__ == \"__main__\":\n",
        "    # WordNet Graph\n",
        "    root_synset = \"dog.n.01\"\n",
        "    G_wordnet = build_wordnet_graph_api(root_synset, depth=2)\n",
        "    data_wordnet = wordnet_to_torch_geometric(G_wordnet)\n",
        "\n",
        "    # ConceptNet Graph\n",
        "    concept = \"dog\"\n",
        "    G_conceptnet = build_conceptnet_graph_api(concept, max_edges=1000)\n",
        "    data_conceptnet = conceptnet_to_torch_geometric(G_conceptnet)\n",
        "\n",
        "    # DataLoader\n",
        "    datasets = {'WordNet': [data_wordnet], 'ConceptNet': [data_conceptnet]}\n",
        "    loaders = {name: DataLoader(data, batch_size=1, shuffle=False) for name, data in datasets.items()}\n",
        "\n",
        "    # Initialize models\n",
        "    input_dim = 16\n",
        "    hidden_dim = 32\n",
        "    output_dim = 2\n",
        "    models = {'GCN': GCN(input_dim, hidden_dim, output_dim),\n",
        "              'GAT': GAT(input_dim, hidden_dim, output_dim),\n",
        "              'MPNN': MPNN(input_dim, hidden_dim, output_dim)}\n",
        "\n",
        "    # Training setup\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for dataset_name, loader in loaders.items():\n",
        "        print(f\"Dataset: {dataset_name}\")\n",
        "        for model_name, model in models.items():\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "            # Train model\n",
        "            for epoch in range(10):\n",
        "                for batch in loader:\n",
        "                    loss = train(model, batch, optimizer, criterion)\n",
        "                print(f\"{model_name} Epoch {epoch+1}, Loss: {loss:.4f}\")\n",
        "\n",
        "            # Evaluate model\n",
        "            mrr, hits_10, avg_loss = evaluate(model, loader, criterion)\n",
        "            print(f\"{model_name} Results on {dataset_name}:\")\n",
        "            print(f\"  MRR: {mrr:.4f}, Hits@10: {hits_10:.4f}, Avg Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCydWmJtYaDT",
        "outputId": "0e309dd7-ce6f-42e3-c2ae-c280d3b4fae8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: WordNet\n",
            "GCN Epoch 1, Loss: 0.6995\n",
            "GCN Epoch 2, Loss: 0.6911\n",
            "GCN Epoch 3, Loss: 0.6927\n",
            "GCN Epoch 4, Loss: 0.6923\n",
            "GCN Epoch 5, Loss: 0.6907\n",
            "GCN Epoch 6, Loss: 0.6899\n",
            "GCN Epoch 7, Loss: 0.6895\n",
            "GCN Epoch 8, Loss: 0.6888\n",
            "GCN Epoch 9, Loss: 0.6881\n",
            "GCN Epoch 10, Loss: 0.6871\n",
            "GCN Results on WordNet:\n",
            "  MRR: 0.7837, Hits@10: 1.0000, Avg Loss: 0.6858\n",
            "GAT Epoch 1, Loss: 0.6948\n",
            "GAT Epoch 2, Loss: 0.6918\n",
            "GAT Epoch 3, Loss: 0.6889\n",
            "GAT Epoch 4, Loss: 0.6872\n",
            "GAT Epoch 5, Loss: 0.6849\n",
            "GAT Epoch 6, Loss: 0.6839\n",
            "GAT Epoch 7, Loss: 0.6817\n",
            "GAT Epoch 8, Loss: 0.6801\n",
            "GAT Epoch 9, Loss: 0.6774\n",
            "GAT Epoch 10, Loss: 0.6749\n",
            "GAT Results on WordNet:\n",
            "  MRR: 0.7877, Hits@10: 1.0000, Avg Loss: 0.6720\n",
            "MPNN Epoch 1, Loss: 0.6969\n",
            "MPNN Epoch 2, Loss: 0.6920\n",
            "MPNN Epoch 3, Loss: 0.6912\n",
            "MPNN Epoch 4, Loss: 0.6906\n",
            "MPNN Epoch 5, Loss: 0.6893\n",
            "MPNN Epoch 6, Loss: 0.6880\n",
            "MPNN Epoch 7, Loss: 0.6866\n",
            "MPNN Epoch 8, Loss: 0.6855\n",
            "MPNN Epoch 9, Loss: 0.6840\n",
            "MPNN Epoch 10, Loss: 0.6825\n",
            "MPNN Results on WordNet:\n",
            "  MRR: 0.7937, Hits@10: 1.0000, Avg Loss: 0.6811\n",
            "Dataset: ConceptNet\n",
            "GCN Epoch 1, Loss: 0.6995\n",
            "GCN Epoch 2, Loss: 0.6794\n",
            "GCN Epoch 3, Loss: 0.6743\n",
            "GCN Epoch 4, Loss: 0.6656\n",
            "GCN Epoch 5, Loss: 0.6578\n",
            "GCN Epoch 6, Loss: 0.6488\n",
            "GCN Epoch 7, Loss: 0.6412\n",
            "GCN Epoch 8, Loss: 0.6333\n",
            "GCN Epoch 9, Loss: 0.6244\n",
            "GCN Epoch 10, Loss: 0.6189\n",
            "GCN Results on ConceptNet:\n",
            "  MRR: 0.8478, Hits@10: 1.0000, Avg Loss: 0.6145\n",
            "GAT Epoch 1, Loss: 0.6815\n",
            "GAT Epoch 2, Loss: 0.6460\n",
            "GAT Epoch 3, Loss: 0.6487\n",
            "GAT Epoch 4, Loss: 0.6313\n",
            "GAT Epoch 5, Loss: 0.6100\n",
            "GAT Epoch 6, Loss: 0.5944\n",
            "GAT Epoch 7, Loss: 0.5853\n",
            "GAT Epoch 8, Loss: 0.5700\n",
            "GAT Epoch 9, Loss: 0.5512\n",
            "GAT Epoch 10, Loss: 0.5378\n",
            "GAT Results on ConceptNet:\n",
            "  MRR: 0.8696, Hits@10: 1.0000, Avg Loss: 0.5248\n",
            "MPNN Epoch 1, Loss: 0.6924\n",
            "MPNN Epoch 2, Loss: 0.6845\n",
            "MPNN Epoch 3, Loss: 0.6798\n",
            "MPNN Epoch 4, Loss: 0.6775\n",
            "MPNN Epoch 5, Loss: 0.6767\n",
            "MPNN Epoch 6, Loss: 0.6768\n",
            "MPNN Epoch 7, Loss: 0.6769\n",
            "MPNN Epoch 8, Loss: 0.6765\n",
            "MPNN Epoch 9, Loss: 0.6756\n",
            "MPNN Epoch 10, Loss: 0.6747\n",
            "MPNN Results on ConceptNet:\n",
            "  MRR: 0.7826, Hits@10: 1.0000, Avg Loss: 0.6740\n"
          ]
        }
      ]
    }
  ]
}